{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'ascii'\n"
     ]
    }
   ],
   "source": [
    "data = xlrd.open_workbook('../data/fire_theft.xls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = data.sheet_by_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = sheet.nrows - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32,name='X')\n",
    "Y = tf.placeholder(dtype=tf.float32,name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(0.0, name='weights',dtype=tf.float32)\n",
    "b = tf.Variable(0.0, name='bias',dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = X*w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.square(y_predicted - Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0 loss:86924.5412027 \n",
      "iteration:1 loss:88914.5190442 \n",
      "iteration:2 loss:87876.7143661 \n",
      "iteration:3 loss:86877.3379401 \n",
      "iteration:4 loss:85914.8297317 \n",
      "iteration:5 loss:84987.615082 \n",
      "iteration:6 loss:84094.2800033 \n",
      "iteration:7 loss:83233.4302298 \n",
      "iteration:8 loss:82403.7665273 \n",
      "iteration:9 loss:81603.9844878 \n",
      "iteration:10 loss:80832.9094593 \n",
      "iteration:11 loss:80089.3749627 \n",
      "iteration:12 loss:79372.2909245 \n",
      "iteration:13 loss:78680.5796213 \n",
      "iteration:14 loss:78013.2712825 \n",
      "iteration:15 loss:77369.3707182 \n",
      "iteration:16 loss:76747.964795 \n",
      "iteration:17 loss:76148.1864348 \n",
      "iteration:18 loss:75569.1755601 \n",
      "iteration:19 loss:75010.1609557 \n",
      "iteration:20 loss:74470.3043831 \n",
      "iteration:21 loss:73948.9434383 \n",
      "iteration:22 loss:73445.3334597 \n",
      "iteration:23 loss:72958.7824577 \n",
      "iteration:24 loss:72488.6766688 \n",
      "iteration:25 loss:72034.3942482 \n",
      "iteration:26 loss:71595.3040081 \n",
      "iteration:27 loss:71170.8779666 \n",
      "iteration:28 loss:70760.5345077 \n",
      "iteration:29 loss:70363.7949407 \n",
      "iteration:30 loss:69980.1286205 \n",
      "iteration:31 loss:69609.0528088 \n",
      "iteration:32 loss:69250.1151658 \n",
      "iteration:33 loss:68902.8511187 \n",
      "iteration:34 loss:68566.8767116 \n",
      "iteration:35 loss:68241.7819236 \n",
      "iteration:36 loss:67927.1325598 \n",
      "iteration:37 loss:67622.6146363 \n",
      "iteration:38 loss:67327.8209403 \n",
      "iteration:39 loss:67042.4125396 \n",
      "iteration:40 loss:66766.0583659 \n",
      "iteration:41 loss:66498.454019 \n",
      "iteration:42 loss:66239.307594 \n",
      "iteration:43 loss:65988.3050007 \n",
      "iteration:44 loss:65745.1611244 \n",
      "iteration:45 loss:65509.5998794 \n",
      "iteration:46 loss:65281.3743311 \n",
      "iteration:47 loss:65060.2237724 \n",
      "iteration:48 loss:64845.9025194 \n",
      "iteration:49 loss:64638.211185 \n",
      "iteration:50 loss:64436.8955075 \n",
      "iteration:51 loss:64241.7446952 \n",
      "iteration:52 loss:64052.551883 \n",
      "iteration:53 loss:63869.1255237 \n",
      "iteration:54 loss:63691.2609274 \n",
      "iteration:55 loss:63518.8009002 \n",
      "iteration:56 loss:63351.5222765 \n",
      "iteration:57 loss:63189.2796699 \n",
      "iteration:58 loss:63031.9463301 \n",
      "iteration:59 loss:62879.3061355 \n",
      "iteration:60 loss:62731.2088574 \n",
      "iteration:61 loss:62587.5389634 \n",
      "iteration:62 loss:62448.1416103 \n",
      "iteration:63 loss:62312.855637 \n",
      "iteration:64 loss:62181.6055827 \n",
      "iteration:65 loss:62054.2064757 \n",
      "iteration:66 loss:61930.5819742 \n",
      "iteration:67 loss:61810.5565419 \n",
      "iteration:68 loss:61694.0652534 \n",
      "iteration:69 loss:61580.9748972 \n",
      "iteration:70 loss:61471.1855654 \n",
      "iteration:71 loss:61364.5791653 \n",
      "iteration:72 loss:61261.0827713 \n",
      "iteration:73 loss:61160.5808928 \n",
      "iteration:74 loss:61062.9924442 \n",
      "iteration:75 loss:60968.2171724 \n",
      "iteration:76 loss:60876.1756349 \n",
      "iteration:77 loss:60786.7777448 \n",
      "iteration:78 loss:60699.9568821 \n",
      "iteration:79 loss:60615.6126524 \n",
      "iteration:80 loss:60533.6849468 \n",
      "iteration:81 loss:60454.0919731 \n",
      "iteration:82 loss:60376.7734467 \n",
      "iteration:83 loss:60301.6689239 \n",
      "iteration:84 loss:60228.6748749 \n",
      "iteration:85 loss:60157.7616102 \n",
      "iteration:86 loss:60088.8604399 \n",
      "iteration:87 loss:60021.906709 \n",
      "iteration:88 loss:59956.8362384 \n",
      "iteration:89 loss:59893.5973906 \n",
      "iteration:90 loss:59832.1424855 \n",
      "iteration:91 loss:59772.4331499 \n",
      "iteration:92 loss:59714.3831278 \n",
      "iteration:93 loss:59657.9549324 \n",
      "iteration:94 loss:59603.1226558 \n",
      "iteration:95 loss:59549.8057888 \n",
      "iteration:96 loss:59497.9950817 \n",
      "iteration:97 loss:59447.6232942 \n",
      "iteration:98 loss:59398.6443923 \n",
      "iteration:99 loss:59351.0519406 \n",
      "iteration:100 loss:59304.7590102 \n",
      "iteration:101 loss:59259.7624268 \n",
      "iteration:102 loss:59216.0130956 \n",
      "iteration:103 loss:59173.4806171 \n",
      "iteration:104 loss:59132.116275 \n",
      "iteration:105 loss:59091.9088351 \n",
      "iteration:106 loss:59052.8080192 \n",
      "iteration:107 loss:59014.7935094 \n",
      "iteration:108 loss:58977.803393 \n",
      "iteration:109 loss:58941.8485696 \n",
      "iteration:110 loss:58906.874432 \n",
      "iteration:111 loss:58872.8685857 \n",
      "iteration:112 loss:58839.7965153 \n",
      "iteration:113 loss:58807.6266642 \n",
      "iteration:114 loss:58776.3391842 \n",
      "iteration:115 loss:58745.912317 \n",
      "iteration:116 loss:58716.3181472 \n",
      "iteration:117 loss:58687.5395288 \n",
      "iteration:118 loss:58659.551764 \n",
      "iteration:119 loss:58632.3192666 \n",
      "iteration:120 loss:58605.8461646 \n",
      "iteration:121 loss:58580.0758262 \n",
      "iteration:122 loss:58555.0067498 \n",
      "iteration:123 loss:58530.6360802 \n",
      "iteration:124 loss:58506.9184404 \n",
      "iteration:125 loss:58483.8566307 \n",
      "iteration:126 loss:58461.4132447 \n",
      "iteration:127 loss:58439.5755669 \n",
      "iteration:128 loss:58418.3529509 \n",
      "iteration:129 loss:58397.6867334 \n",
      "iteration:130 loss:58377.5924565 \n",
      "iteration:131 loss:58358.038124 \n",
      "iteration:132 loss:58339.0139545 \n",
      "iteration:133 loss:58320.5018954 \n",
      "iteration:134 loss:58302.4993556 \n",
      "iteration:135 loss:58284.9663043 \n",
      "iteration:136 loss:58267.9293899 \n",
      "iteration:137 loss:58251.3454521 \n",
      "iteration:138 loss:58235.2117358 \n",
      "iteration:139 loss:58219.50556 \n",
      "iteration:140 loss:58204.232302 \n",
      "iteration:141 loss:58189.3682119 \n",
      "iteration:142 loss:58174.894779 \n",
      "iteration:143 loss:58160.8241789 \n",
      "iteration:144 loss:58147.1296698 \n",
      "iteration:145 loss:58133.8100695 \n",
      "iteration:146 loss:58120.8376346 \n",
      "iteration:147 loss:58108.2163866 \n",
      "iteration:148 loss:58095.930478 \n",
      "iteration:149 loss:58083.9869034 \n",
      "iteration:150 loss:58072.3587618 \n",
      "iteration:151 loss:58061.0491903 \n",
      "iteration:152 loss:58050.0150726 \n",
      "iteration:153 loss:58039.2965507 \n",
      "iteration:154 loss:58028.865024 \n",
      "iteration:155 loss:58018.7277867 \n",
      "iteration:156 loss:58008.8569361 \n",
      "iteration:157 loss:57999.2509979 \n",
      "iteration:158 loss:57989.9047852 \n",
      "iteration:159 loss:57980.7932301 \n",
      "iteration:160 loss:57971.9346802 \n",
      "iteration:161 loss:57963.3352384 \n",
      "iteration:162 loss:57954.9377481 \n",
      "iteration:163 loss:57946.7700724 \n",
      "iteration:164 loss:57938.814941 \n",
      "iteration:165 loss:57931.0801811 \n",
      "iteration:166 loss:57923.5542657 \n",
      "iteration:167 loss:57916.2272804 \n",
      "iteration:168 loss:57909.1047365 \n",
      "iteration:169 loss:57902.1523622 \n",
      "iteration:170 loss:57895.401969 \n",
      "iteration:171 loss:57888.8324873 \n",
      "iteration:172 loss:57882.4476546 \n",
      "iteration:173 loss:57876.2248311 \n",
      "iteration:174 loss:57870.1715181 \n",
      "iteration:175 loss:57864.2746291 \n",
      "iteration:176 loss:57858.5466685 \n",
      "iteration:177 loss:57852.9535338 \n",
      "iteration:178 loss:57847.5241573 \n",
      "iteration:179 loss:57842.2505642 \n",
      "iteration:180 loss:57837.1113398 \n",
      "iteration:181 loss:57832.0853252 \n",
      "iteration:182 loss:57827.2066429 \n",
      "iteration:183 loss:57822.4636436 \n",
      "iteration:184 loss:57817.8536014 \n",
      "iteration:185 loss:57813.3794228 \n",
      "iteration:186 loss:57808.9772559 \n",
      "iteration:187 loss:57804.7102966 \n",
      "iteration:188 loss:57800.5809507 \n",
      "iteration:189 loss:57796.5262903 \n",
      "iteration:190 loss:57792.5997168 \n",
      "iteration:191 loss:57788.774144 \n",
      "iteration:192 loss:57785.0493171 \n",
      "iteration:193 loss:57781.4371954 \n",
      "iteration:194 loss:57777.9090902 \n",
      "iteration:195 loss:57774.4790052 \n",
      "iteration:196 loss:57771.1518414 \n",
      "iteration:197 loss:57767.9024601 \n",
      "iteration:198 loss:57764.7391708 \n",
      "iteration:199 loss:57761.6594055 \n",
      "iteration:200 loss:57758.6628354 \n",
      "iteration:201 loss:57755.7411488 \n",
      "iteration:202 loss:57752.9056246 \n",
      "iteration:203 loss:57750.1434091 \n",
      "iteration:204 loss:57747.4412846 \n",
      "iteration:205 loss:57744.8205488 \n",
      "iteration:206 loss:57742.2820437 \n",
      "iteration:207 loss:57739.8029047 \n",
      "iteration:208 loss:57737.3773708 \n",
      "iteration:209 loss:57735.0216674 \n",
      "iteration:210 loss:57732.7339073 \n",
      "iteration:211 loss:57730.5044715 \n",
      "iteration:212 loss:57728.3400315 \n",
      "iteration:213 loss:57726.2354101 \n",
      "iteration:214 loss:57724.1894617 \n",
      "iteration:215 loss:57722.1759775 \n",
      "iteration:216 loss:57720.2378555 \n",
      "iteration:217 loss:57718.3354521 \n",
      "iteration:218 loss:57716.4877303 \n",
      "iteration:219 loss:57714.7000539 \n",
      "iteration:220 loss:57712.9626032 \n",
      "iteration:221 loss:57711.271031 \n",
      "iteration:222 loss:57709.6152634 \n",
      "iteration:223 loss:57707.9976849 \n",
      "iteration:224 loss:57706.4134663 \n",
      "iteration:225 loss:57704.8878925 \n",
      "iteration:226 loss:57703.3994053 \n",
      "iteration:227 loss:57701.9615979 \n",
      "iteration:228 loss:57700.5488362 \n",
      "iteration:229 loss:57699.1617336 \n",
      "iteration:230 loss:57697.8514149 \n",
      "iteration:231 loss:57696.5391476 \n",
      "iteration:232 loss:57695.2697163 \n",
      "iteration:233 loss:57694.0441785 \n",
      "iteration:234 loss:57692.8356949 \n",
      "iteration:235 loss:57691.6775277 \n",
      "iteration:236 loss:57690.5445525 \n",
      "iteration:237 loss:57689.4424706 \n",
      "iteration:238 loss:57688.3861559 \n",
      "iteration:239 loss:57687.3208199 \n",
      "iteration:240 loss:57686.3125342 \n",
      "iteration:241 loss:57685.3245968 \n",
      "iteration:242 loss:57684.3492537 \n",
      "iteration:243 loss:57683.4088308 \n",
      "iteration:244 loss:57682.4965103 \n",
      "iteration:245 loss:57681.6039396 \n",
      "iteration:246 loss:57680.7413679 \n",
      "iteration:247 loss:57679.9108419 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:248 loss:57679.0914784 \n",
      "iteration:249 loss:57678.2968591 \n",
      "iteration:250 loss:57677.5097307 \n",
      "iteration:251 loss:57676.7663462 \n",
      "iteration:252 loss:57676.0078867 \n",
      "iteration:253 loss:57675.2977763 \n",
      "iteration:254 loss:57674.5780476 \n",
      "iteration:255 loss:57673.9202395 \n",
      "iteration:256 loss:57673.2535067 \n",
      "iteration:257 loss:57672.6152483 \n",
      "iteration:258 loss:57671.9883851 \n",
      "iteration:259 loss:57671.3709053 \n",
      "iteration:260 loss:57670.7992076 \n",
      "iteration:261 loss:57670.2133327 \n",
      "iteration:262 loss:57669.6474698 \n",
      "iteration:263 loss:57669.0932066 \n",
      "iteration:264 loss:57668.5641161 \n",
      "iteration:265 loss:57668.05497 \n",
      "iteration:266 loss:57667.5315677 \n",
      "iteration:267 loss:57667.0484688 \n",
      "iteration:268 loss:57666.5619416 \n",
      "iteration:269 loss:57666.0954233 \n",
      "iteration:270 loss:57665.6328319 \n",
      "iteration:271 loss:57665.1884957 \n",
      "iteration:272 loss:57664.7631605 \n",
      "iteration:273 loss:57664.3388485 \n",
      "iteration:274 loss:57663.9351816 \n",
      "iteration:275 loss:57663.5347812 \n",
      "iteration:276 loss:57663.1509326 \n",
      "iteration:277 loss:57662.7691588 \n",
      "iteration:278 loss:57662.3979472 \n",
      "iteration:279 loss:57662.0567813 \n",
      "iteration:280 loss:57661.7063207 \n",
      "iteration:281 loss:57661.3737673 \n",
      "iteration:282 loss:57661.0404604 \n",
      "iteration:283 loss:57660.731544 \n",
      "iteration:284 loss:57660.4056636 \n",
      "iteration:285 loss:57660.1064102 \n",
      "iteration:286 loss:57659.821734 \n",
      "iteration:287 loss:57659.5296456 \n",
      "iteration:288 loss:57659.2459135 \n",
      "iteration:289 loss:57658.9729126 \n",
      "iteration:290 loss:57658.7129804 \n",
      "iteration:291 loss:57658.4483806 \n",
      "iteration:292 loss:57658.2061434 \n",
      "iteration:293 loss:57657.9583444 \n",
      "iteration:294 loss:57657.7262528 \n",
      "iteration:295 loss:57657.48729 \n",
      "iteration:296 loss:57657.2560675 \n",
      "iteration:297 loss:57657.0336226 \n",
      "iteration:298 loss:57656.8302736 \n",
      "iteration:299 loss:57656.6347208 \n",
      "iteration:300 loss:57656.430099 \n",
      "iteration:301 loss:57656.2272934 \n",
      "iteration:302 loss:57656.0493748 \n",
      "iteration:303 loss:57655.8700686 \n",
      "iteration:304 loss:57655.6766195 \n",
      "iteration:305 loss:57655.5027006 \n",
      "iteration:306 loss:57655.3355861 \n",
      "iteration:307 loss:57655.1692733 \n",
      "iteration:308 loss:57655.0124823 \n",
      "iteration:309 loss:57654.854705 \n",
      "iteration:310 loss:57654.7086454 \n",
      "iteration:311 loss:57654.571376 \n",
      "iteration:312 loss:57654.408351 \n",
      "iteration:313 loss:57654.2735208 \n",
      "iteration:314 loss:57654.1252715 \n",
      "iteration:315 loss:57653.9928066 \n",
      "iteration:316 loss:57653.8575284 \n",
      "iteration:317 loss:57653.7402258 \n",
      "iteration:318 loss:57653.5848339 \n",
      "iteration:319 loss:57653.4760921 \n",
      "iteration:320 loss:57653.345109 \n",
      "iteration:321 loss:57653.2262968 \n",
      "iteration:322 loss:57653.1107593 \n",
      "iteration:323 loss:57653.0139821 \n",
      "iteration:324 loss:57652.9030511 \n",
      "iteration:325 loss:57652.7973723 \n",
      "iteration:326 loss:57652.7035796 \n",
      "iteration:327 loss:57652.6171113 \n",
      "iteration:328 loss:57652.5388438 \n",
      "iteration:329 loss:57652.4409394 \n",
      "iteration:330 loss:57652.3461146 \n",
      "iteration:331 loss:57652.2679915 \n",
      "iteration:332 loss:57652.1806049 \n",
      "iteration:333 loss:57652.0837024 \n",
      "iteration:334 loss:57652.0159812 \n",
      "iteration:335 loss:57651.9470852 \n",
      "iteration:336 loss:57651.8645941 \n",
      "iteration:337 loss:57651.7786806 \n",
      "iteration:338 loss:57651.6908996 \n",
      "iteration:339 loss:57651.6136552 \n",
      "iteration:340 loss:57651.5489078 \n",
      "iteration:341 loss:57651.4707138 \n",
      "iteration:342 loss:57651.4135368 \n",
      "iteration:343 loss:57651.3508732 \n",
      "iteration:344 loss:57651.2939088 \n",
      "iteration:345 loss:57651.2231848 \n",
      "iteration:346 loss:57651.1629815 \n",
      "iteration:347 loss:57651.1303797 \n",
      "iteration:348 loss:57651.0779754 \n",
      "iteration:349 loss:57651.0224398 \n",
      "iteration:350 loss:57650.9707061 \n",
      "iteration:351 loss:57650.9181895 \n",
      "iteration:352 loss:57650.8722521 \n",
      "iteration:353 loss:57650.8201228 \n",
      "iteration:354 loss:57650.7759202 \n",
      "iteration:355 loss:57650.708222 \n",
      "iteration:356 loss:57650.6740017 \n",
      "iteration:357 loss:57650.6271562 \n",
      "iteration:358 loss:57650.5893783 \n",
      "iteration:359 loss:57650.5519103 \n",
      "iteration:360 loss:57650.5089466 \n",
      "iteration:361 loss:57650.4799392 \n",
      "iteration:362 loss:57650.431156 \n",
      "iteration:363 loss:57650.401052 \n",
      "iteration:364 loss:57650.3687982 \n",
      "iteration:365 loss:57650.330916 \n",
      "iteration:366 loss:57650.2910165 \n",
      "iteration:367 loss:57650.2709055 \n",
      "iteration:368 loss:57650.239898 \n",
      "iteration:369 loss:57650.2098927 \n",
      "iteration:370 loss:57650.1911558 \n",
      "iteration:371 loss:57650.1521102 \n",
      "iteration:372 loss:57650.1215412 \n",
      "iteration:373 loss:57650.0949796 \n",
      "iteration:374 loss:57650.0838482 \n",
      "iteration:375 loss:57650.047934 \n",
      "iteration:376 loss:57650.0366019 \n",
      "iteration:377 loss:57650.0116901 \n",
      "iteration:378 loss:57649.9977097 \n",
      "iteration:379 loss:57649.9703649 \n",
      "iteration:380 loss:57649.946429 \n",
      "iteration:381 loss:57649.9327953 \n",
      "iteration:382 loss:57649.911987 \n",
      "iteration:383 loss:57649.9040003 \n",
      "iteration:384 loss:57649.8914504 \n",
      "iteration:385 loss:57649.8676642 \n",
      "iteration:386 loss:57649.8585082 \n",
      "iteration:387 loss:57649.8471114 \n",
      "iteration:388 loss:57649.8364014 \n",
      "iteration:389 loss:57649.8363673 \n",
      "iteration:390 loss:57649.8236311 \n",
      "iteration:391 loss:57649.8101812 \n",
      "iteration:392 loss:57649.8217987 \n",
      "iteration:393 loss:57649.801834 \n",
      "iteration:394 loss:57649.7980252 \n",
      "iteration:395 loss:57649.7978894 \n",
      "iteration:396 loss:57649.8006458 \n",
      "iteration:397 loss:57649.7822299 \n",
      "iteration:398 loss:57649.7783117 \n",
      "iteration:399 loss:57649.774894 \n",
      "iteration:400 loss:57649.7688064 \n",
      "iteration:401 loss:57649.7680661 \n",
      "iteration:402 loss:57649.7551003 \n",
      "iteration:403 loss:57649.7551039 \n",
      "iteration:404 loss:57649.7404777 \n",
      "iteration:405 loss:57649.7386647 \n",
      "iteration:406 loss:57649.7368971 \n",
      "iteration:407 loss:57649.7267297 \n",
      "iteration:408 loss:57649.7205934 \n",
      "iteration:409 loss:57649.720118 \n",
      "iteration:410 loss:57649.7061836 \n",
      "iteration:411 loss:57649.7020163 \n",
      "iteration:412 loss:57649.7048402 \n",
      "iteration:413 loss:57649.6936404 \n",
      "iteration:414 loss:57649.6717111 \n",
      "iteration:415 loss:57649.6730972 \n",
      "iteration:416 loss:57649.6705831 \n",
      "iteration:417 loss:57649.6620816 \n",
      "iteration:418 loss:57649.660514 \n",
      "iteration:419 loss:57649.6630374 \n",
      "iteration:420 loss:57649.65291 \n",
      "iteration:421 loss:57649.6497786 \n",
      "iteration:422 loss:57649.6412322 \n",
      "iteration:423 loss:57649.6376087 \n",
      "iteration:424 loss:57649.6407053 \n",
      "iteration:425 loss:57649.621006 \n",
      "iteration:426 loss:57649.6201707 \n",
      "iteration:427 loss:57649.6224507 \n",
      "iteration:428 loss:57649.6058782 \n",
      "iteration:429 loss:57649.6045602 \n",
      "iteration:430 loss:57649.6039872 \n",
      "iteration:431 loss:57649.5959964 \n",
      "iteration:432 loss:57649.5856765 \n",
      "iteration:433 loss:57649.5777098 \n",
      "iteration:434 loss:57649.5727299 \n",
      "iteration:435 loss:57649.5712257 \n",
      "iteration:436 loss:57649.5634588 \n",
      "iteration:437 loss:57649.5616659 \n",
      "iteration:438 loss:57649.5521898 \n",
      "iteration:439 loss:57649.5609646 \n",
      "iteration:440 loss:57649.5445077 \n",
      "iteration:441 loss:57649.5325551 \n",
      "iteration:442 loss:57649.5316934 \n",
      "iteration:443 loss:57649.5199597 \n",
      "iteration:444 loss:57649.5265428 \n",
      "iteration:445 loss:57649.5196227 \n",
      "iteration:446 loss:57649.5179602 \n",
      "iteration:447 loss:57649.5054015 \n",
      "iteration:448 loss:57649.509683 \n",
      "iteration:449 loss:57649.4980255 \n",
      "iteration:450 loss:57649.4860289 \n",
      "iteration:451 loss:57649.4744384 \n",
      "iteration:452 loss:57649.4787397 \n",
      "iteration:453 loss:57649.4635203 \n",
      "iteration:454 loss:57649.4756283 \n",
      "iteration:455 loss:57649.4645524 \n",
      "iteration:456 loss:57649.4596921 \n",
      "iteration:457 loss:57649.4537354 \n",
      "iteration:458 loss:57649.4453801 \n",
      "iteration:459 loss:57649.4348074 \n",
      "iteration:460 loss:57649.4346577 \n",
      "iteration:461 loss:57649.4308418 \n",
      "iteration:462 loss:57649.429638 \n",
      "iteration:463 loss:57649.429675 \n",
      "iteration:464 loss:57649.429675 \n",
      "iteration:465 loss:57649.429675 \n",
      "iteration:466 loss:57649.429675 \n",
      "iteration:467 loss:57649.429675 \n",
      "iteration:468 loss:57649.429675 \n",
      "iteration:469 loss:57649.429675 \n",
      "iteration:470 loss:57649.429675 \n",
      "iteration:471 loss:57649.429675 \n",
      "iteration:472 loss:57649.429675 \n",
      "iteration:473 loss:57649.429675 \n",
      "iteration:474 loss:57649.429675 \n",
      "iteration:475 loss:57649.429675 \n",
      "iteration:476 loss:57649.429675 \n",
      "iteration:477 loss:57649.429675 \n",
      "iteration:478 loss:57649.429675 \n",
      "iteration:479 loss:57649.429675 \n",
      "iteration:480 loss:57649.429675 \n",
      "iteration:481 loss:57649.429675 \n",
      "iteration:482 loss:57649.429675 \n",
      "iteration:483 loss:57649.429675 \n",
      "iteration:484 loss:57649.429675 \n",
      "iteration:485 loss:57649.429675 \n",
      "iteration:486 loss:57649.429675 \n",
      "iteration:487 loss:57649.429675 \n",
      "iteration:488 loss:57649.429675 \n",
      "iteration:489 loss:57649.429675 \n",
      "iteration:490 loss:57649.429675 \n",
      "iteration:491 loss:57649.429675 \n",
      "iteration:492 loss:57649.429675 \n",
      "iteration:493 loss:57649.429675 \n",
      "iteration:494 loss:57649.429675 \n",
      "iteration:495 loss:57649.429675 \n",
      "iteration:496 loss:57649.429675 \n",
      "iteration:497 loss:57649.429675 \n",
      "iteration:498 loss:57649.429675 \n",
      "iteration:499 loss:57649.429675 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:500 loss:57649.429675 \n",
      "iteration:501 loss:57649.429675 \n",
      "iteration:502 loss:57649.429675 \n",
      "iteration:503 loss:57649.429675 \n",
      "iteration:504 loss:57649.429675 \n",
      "iteration:505 loss:57649.429675 \n",
      "iteration:506 loss:57649.429675 \n",
      "iteration:507 loss:57649.429675 \n",
      "iteration:508 loss:57649.429675 \n",
      "iteration:509 loss:57649.429675 \n",
      "iteration:510 loss:57649.429675 \n",
      "iteration:511 loss:57649.429675 \n",
      "iteration:512 loss:57649.429675 \n",
      "iteration:513 loss:57649.429675 \n",
      "iteration:514 loss:57649.429675 \n",
      "iteration:515 loss:57649.429675 \n",
      "iteration:516 loss:57649.429675 \n",
      "iteration:517 loss:57649.429675 \n",
      "iteration:518 loss:57649.429675 \n",
      "iteration:519 loss:57649.429675 \n",
      "iteration:520 loss:57649.429675 \n",
      "iteration:521 loss:57649.429675 \n",
      "iteration:522 loss:57649.429675 \n",
      "iteration:523 loss:57649.429675 \n",
      "iteration:524 loss:57649.429675 \n",
      "iteration:525 loss:57649.429675 \n",
      "iteration:526 loss:57649.429675 \n",
      "iteration:527 loss:57649.429675 \n",
      "iteration:528 loss:57649.429675 \n",
      "iteration:529 loss:57649.429675 \n",
      "iteration:530 loss:57649.429675 \n",
      "iteration:531 loss:57649.429675 \n",
      "iteration:532 loss:57649.429675 \n",
      "iteration:533 loss:57649.429675 \n",
      "iteration:534 loss:57649.429675 \n",
      "iteration:535 loss:57649.429675 \n",
      "iteration:536 loss:57649.429675 \n",
      "iteration:537 loss:57649.429675 \n",
      "iteration:538 loss:57649.429675 \n",
      "iteration:539 loss:57649.429675 \n",
      "iteration:540 loss:57649.429675 \n",
      "iteration:541 loss:57649.429675 \n",
      "iteration:542 loss:57649.429675 \n",
      "iteration:543 loss:57649.429675 \n",
      "iteration:544 loss:57649.429675 \n",
      "iteration:545 loss:57649.429675 \n",
      "iteration:546 loss:57649.429675 \n",
      "iteration:547 loss:57649.429675 \n",
      "iteration:548 loss:57649.429675 \n",
      "iteration:549 loss:57649.429675 \n",
      "iteration:550 loss:57649.429675 \n",
      "iteration:551 loss:57649.429675 \n",
      "iteration:552 loss:57649.429675 \n",
      "iteration:553 loss:57649.429675 \n",
      "iteration:554 loss:57649.429675 \n",
      "iteration:555 loss:57649.429675 \n",
      "iteration:556 loss:57649.429675 \n",
      "iteration:557 loss:57649.429675 \n",
      "iteration:558 loss:57649.429675 \n",
      "iteration:559 loss:57649.429675 \n",
      "iteration:560 loss:57649.429675 \n",
      "iteration:561 loss:57649.429675 \n",
      "iteration:562 loss:57649.429675 \n",
      "iteration:563 loss:57649.429675 \n",
      "iteration:564 loss:57649.429675 \n",
      "iteration:565 loss:57649.429675 \n",
      "iteration:566 loss:57649.429675 \n",
      "iteration:567 loss:57649.429675 \n",
      "iteration:568 loss:57649.429675 \n",
      "iteration:569 loss:57649.429675 \n",
      "iteration:570 loss:57649.429675 \n",
      "iteration:571 loss:57649.429675 \n",
      "iteration:572 loss:57649.429675 \n",
      "iteration:573 loss:57649.429675 \n",
      "iteration:574 loss:57649.429675 \n",
      "iteration:575 loss:57649.429675 \n",
      "iteration:576 loss:57649.429675 \n",
      "iteration:577 loss:57649.429675 \n",
      "iteration:578 loss:57649.429675 \n",
      "iteration:579 loss:57649.429675 \n",
      "iteration:580 loss:57649.429675 \n",
      "iteration:581 loss:57649.429675 \n",
      "iteration:582 loss:57649.429675 \n",
      "iteration:583 loss:57649.429675 \n",
      "iteration:584 loss:57649.429675 \n",
      "iteration:585 loss:57649.429675 \n",
      "iteration:586 loss:57649.429675 \n",
      "iteration:587 loss:57649.429675 \n",
      "iteration:588 loss:57649.429675 \n",
      "iteration:589 loss:57649.429675 \n",
      "iteration:590 loss:57649.429675 \n",
      "iteration:591 loss:57649.429675 \n",
      "iteration:592 loss:57649.429675 \n",
      "iteration:593 loss:57649.429675 \n",
      "iteration:594 loss:57649.429675 \n",
      "iteration:595 loss:57649.429675 \n",
      "iteration:596 loss:57649.429675 \n",
      "iteration:597 loss:57649.429675 \n",
      "iteration:598 loss:57649.429675 \n",
      "iteration:599 loss:57649.429675 \n",
      "iteration:600 loss:57649.429675 \n",
      "iteration:601 loss:57649.429675 \n",
      "iteration:602 loss:57649.429675 \n",
      "iteration:603 loss:57649.429675 \n",
      "iteration:604 loss:57649.429675 \n",
      "iteration:605 loss:57649.429675 \n",
      "iteration:606 loss:57649.429675 \n",
      "iteration:607 loss:57649.429675 \n",
      "iteration:608 loss:57649.429675 \n",
      "iteration:609 loss:57649.429675 \n",
      "iteration:610 loss:57649.429675 \n",
      "iteration:611 loss:57649.429675 \n",
      "iteration:612 loss:57649.429675 \n",
      "iteration:613 loss:57649.429675 \n",
      "iteration:614 loss:57649.429675 \n",
      "iteration:615 loss:57649.429675 \n",
      "iteration:616 loss:57649.429675 \n",
      "iteration:617 loss:57649.429675 \n",
      "iteration:618 loss:57649.429675 \n",
      "iteration:619 loss:57649.429675 \n",
      "iteration:620 loss:57649.429675 \n",
      "iteration:621 loss:57649.429675 \n",
      "iteration:622 loss:57649.429675 \n",
      "iteration:623 loss:57649.429675 \n",
      "iteration:624 loss:57649.429675 \n",
      "iteration:625 loss:57649.429675 \n",
      "iteration:626 loss:57649.429675 \n",
      "iteration:627 loss:57649.429675 \n",
      "iteration:628 loss:57649.429675 \n",
      "iteration:629 loss:57649.429675 \n",
      "iteration:630 loss:57649.429675 \n",
      "iteration:631 loss:57649.429675 \n",
      "iteration:632 loss:57649.429675 \n",
      "iteration:633 loss:57649.429675 \n",
      "iteration:634 loss:57649.429675 \n",
      "iteration:635 loss:57649.429675 \n",
      "iteration:636 loss:57649.429675 \n",
      "iteration:637 loss:57649.429675 \n",
      "iteration:638 loss:57649.429675 \n",
      "iteration:639 loss:57649.429675 \n",
      "iteration:640 loss:57649.429675 \n",
      "iteration:641 loss:57649.429675 \n",
      "iteration:642 loss:57649.429675 \n",
      "iteration:643 loss:57649.429675 \n",
      "iteration:644 loss:57649.429675 \n",
      "iteration:645 loss:57649.429675 \n",
      "iteration:646 loss:57649.429675 \n",
      "iteration:647 loss:57649.429675 \n",
      "iteration:648 loss:57649.429675 \n",
      "iteration:649 loss:57649.429675 \n",
      "iteration:650 loss:57649.429675 \n",
      "iteration:651 loss:57649.429675 \n",
      "iteration:652 loss:57649.429675 \n",
      "iteration:653 loss:57649.429675 \n",
      "iteration:654 loss:57649.429675 \n",
      "iteration:655 loss:57649.429675 \n",
      "iteration:656 loss:57649.429675 \n",
      "iteration:657 loss:57649.429675 \n",
      "iteration:658 loss:57649.429675 \n",
      "iteration:659 loss:57649.429675 \n",
      "iteration:660 loss:57649.429675 \n",
      "iteration:661 loss:57649.429675 \n",
      "iteration:662 loss:57649.429675 \n",
      "iteration:663 loss:57649.429675 \n",
      "iteration:664 loss:57649.429675 \n",
      "iteration:665 loss:57649.429675 \n",
      "iteration:666 loss:57649.429675 \n",
      "iteration:667 loss:57649.429675 \n",
      "iteration:668 loss:57649.429675 \n",
      "iteration:669 loss:57649.429675 \n",
      "iteration:670 loss:57649.429675 \n",
      "iteration:671 loss:57649.429675 \n",
      "iteration:672 loss:57649.429675 \n",
      "iteration:673 loss:57649.429675 \n",
      "iteration:674 loss:57649.429675 \n",
      "iteration:675 loss:57649.429675 \n",
      "iteration:676 loss:57649.429675 \n",
      "iteration:677 loss:57649.429675 \n",
      "iteration:678 loss:57649.429675 \n",
      "iteration:679 loss:57649.429675 \n",
      "iteration:680 loss:57649.429675 \n",
      "iteration:681 loss:57649.429675 \n",
      "iteration:682 loss:57649.429675 \n",
      "iteration:683 loss:57649.429675 \n",
      "iteration:684 loss:57649.429675 \n",
      "iteration:685 loss:57649.429675 \n",
      "iteration:686 loss:57649.429675 \n",
      "iteration:687 loss:57649.429675 \n",
      "iteration:688 loss:57649.429675 \n",
      "iteration:689 loss:57649.429675 \n",
      "iteration:690 loss:57649.429675 \n",
      "iteration:691 loss:57649.429675 \n",
      "iteration:692 loss:57649.429675 \n",
      "iteration:693 loss:57649.429675 \n",
      "iteration:694 loss:57649.429675 \n",
      "iteration:695 loss:57649.429675 \n",
      "iteration:696 loss:57649.429675 \n",
      "iteration:697 loss:57649.429675 \n",
      "iteration:698 loss:57649.429675 \n",
      "iteration:699 loss:57649.429675 \n",
      "iteration:700 loss:57649.429675 \n",
      "iteration:701 loss:57649.429675 \n",
      "iteration:702 loss:57649.429675 \n",
      "iteration:703 loss:57649.429675 \n",
      "iteration:704 loss:57649.429675 \n",
      "iteration:705 loss:57649.429675 \n",
      "iteration:706 loss:57649.429675 \n",
      "iteration:707 loss:57649.429675 \n",
      "iteration:708 loss:57649.429675 \n",
      "iteration:709 loss:57649.429675 \n",
      "iteration:710 loss:57649.429675 \n",
      "iteration:711 loss:57649.429675 \n",
      "iteration:712 loss:57649.429675 \n",
      "iteration:713 loss:57649.429675 \n",
      "iteration:714 loss:57649.429675 \n",
      "iteration:715 loss:57649.429675 \n",
      "iteration:716 loss:57649.429675 \n",
      "iteration:717 loss:57649.429675 \n",
      "iteration:718 loss:57649.429675 \n",
      "iteration:719 loss:57649.429675 \n",
      "iteration:720 loss:57649.429675 \n",
      "iteration:721 loss:57649.429675 \n",
      "iteration:722 loss:57649.429675 \n",
      "iteration:723 loss:57649.429675 \n",
      "iteration:724 loss:57649.429675 \n",
      "iteration:725 loss:57649.429675 \n",
      "iteration:726 loss:57649.429675 \n",
      "iteration:727 loss:57649.429675 \n",
      "iteration:728 loss:57649.429675 \n",
      "iteration:729 loss:57649.429675 \n",
      "iteration:730 loss:57649.429675 \n",
      "iteration:731 loss:57649.429675 \n",
      "iteration:732 loss:57649.429675 \n",
      "iteration:733 loss:57649.429675 \n",
      "iteration:734 loss:57649.429675 \n",
      "iteration:735 loss:57649.429675 \n",
      "iteration:736 loss:57649.429675 \n",
      "iteration:737 loss:57649.429675 \n",
      "iteration:738 loss:57649.429675 \n",
      "iteration:739 loss:57649.429675 \n",
      "iteration:740 loss:57649.429675 \n",
      "iteration:741 loss:57649.429675 \n",
      "iteration:742 loss:57649.429675 \n",
      "iteration:743 loss:57649.429675 \n",
      "iteration:744 loss:57649.429675 \n",
      "iteration:745 loss:57649.429675 \n",
      "iteration:746 loss:57649.429675 \n",
      "iteration:747 loss:57649.429675 \n",
      "iteration:748 loss:57649.429675 \n",
      "iteration:749 loss:57649.429675 \n",
      "iteration:750 loss:57649.429675 \n",
      "iteration:751 loss:57649.429675 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:752 loss:57649.429675 \n",
      "iteration:753 loss:57649.429675 \n",
      "iteration:754 loss:57649.429675 \n",
      "iteration:755 loss:57649.429675 \n",
      "iteration:756 loss:57649.429675 \n",
      "iteration:757 loss:57649.429675 \n",
      "iteration:758 loss:57649.429675 \n",
      "iteration:759 loss:57649.429675 \n",
      "iteration:760 loss:57649.429675 \n",
      "iteration:761 loss:57649.429675 \n",
      "iteration:762 loss:57649.429675 \n",
      "iteration:763 loss:57649.429675 \n",
      "iteration:764 loss:57649.429675 \n",
      "iteration:765 loss:57649.429675 \n",
      "iteration:766 loss:57649.429675 \n",
      "iteration:767 loss:57649.429675 \n",
      "iteration:768 loss:57649.429675 \n",
      "iteration:769 loss:57649.429675 \n",
      "iteration:770 loss:57649.429675 \n",
      "iteration:771 loss:57649.429675 \n",
      "iteration:772 loss:57649.429675 \n",
      "iteration:773 loss:57649.429675 \n",
      "iteration:774 loss:57649.429675 \n",
      "iteration:775 loss:57649.429675 \n",
      "iteration:776 loss:57649.429675 \n",
      "iteration:777 loss:57649.429675 \n",
      "iteration:778 loss:57649.429675 \n",
      "iteration:779 loss:57649.429675 \n",
      "iteration:780 loss:57649.429675 \n",
      "iteration:781 loss:57649.429675 \n",
      "iteration:782 loss:57649.429675 \n",
      "iteration:783 loss:57649.429675 \n",
      "iteration:784 loss:57649.429675 \n",
      "iteration:785 loss:57649.429675 \n",
      "iteration:786 loss:57649.429675 \n",
      "iteration:787 loss:57649.429675 \n",
      "iteration:788 loss:57649.429675 \n",
      "iteration:789 loss:57649.429675 \n",
      "iteration:790 loss:57649.429675 \n",
      "iteration:791 loss:57649.429675 \n",
      "iteration:792 loss:57649.429675 \n",
      "iteration:793 loss:57649.429675 \n",
      "iteration:794 loss:57649.429675 \n",
      "iteration:795 loss:57649.429675 \n",
      "iteration:796 loss:57649.429675 \n",
      "iteration:797 loss:57649.429675 \n",
      "iteration:798 loss:57649.429675 \n",
      "iteration:799 loss:57649.429675 \n",
      "iteration:800 loss:57649.429675 \n",
      "iteration:801 loss:57649.429675 \n",
      "iteration:802 loss:57649.429675 \n",
      "iteration:803 loss:57649.429675 \n",
      "iteration:804 loss:57649.429675 \n",
      "iteration:805 loss:57649.429675 \n",
      "iteration:806 loss:57649.429675 \n",
      "iteration:807 loss:57649.429675 \n",
      "iteration:808 loss:57649.429675 \n",
      "iteration:809 loss:57649.429675 \n",
      "iteration:810 loss:57649.429675 \n",
      "iteration:811 loss:57649.429675 \n",
      "iteration:812 loss:57649.429675 \n",
      "iteration:813 loss:57649.429675 \n",
      "iteration:814 loss:57649.429675 \n",
      "iteration:815 loss:57649.429675 \n",
      "iteration:816 loss:57649.429675 \n",
      "iteration:817 loss:57649.429675 \n",
      "iteration:818 loss:57649.429675 \n",
      "iteration:819 loss:57649.429675 \n",
      "iteration:820 loss:57649.429675 \n",
      "iteration:821 loss:57649.429675 \n",
      "iteration:822 loss:57649.429675 \n",
      "iteration:823 loss:57649.429675 \n",
      "iteration:824 loss:57649.429675 \n",
      "iteration:825 loss:57649.429675 \n",
      "iteration:826 loss:57649.429675 \n",
      "iteration:827 loss:57649.429675 \n",
      "iteration:828 loss:57649.429675 \n",
      "iteration:829 loss:57649.429675 \n",
      "iteration:830 loss:57649.429675 \n",
      "iteration:831 loss:57649.429675 \n",
      "iteration:832 loss:57649.429675 \n",
      "iteration:833 loss:57649.429675 \n",
      "iteration:834 loss:57649.429675 \n",
      "iteration:835 loss:57649.429675 \n",
      "iteration:836 loss:57649.429675 \n",
      "iteration:837 loss:57649.429675 \n",
      "iteration:838 loss:57649.429675 \n",
      "iteration:839 loss:57649.429675 \n",
      "iteration:840 loss:57649.429675 \n",
      "iteration:841 loss:57649.429675 \n",
      "iteration:842 loss:57649.429675 \n",
      "iteration:843 loss:57649.429675 \n",
      "iteration:844 loss:57649.429675 \n",
      "iteration:845 loss:57649.429675 \n",
      "iteration:846 loss:57649.429675 \n",
      "iteration:847 loss:57649.429675 \n",
      "iteration:848 loss:57649.429675 \n",
      "iteration:849 loss:57649.429675 \n",
      "iteration:850 loss:57649.429675 \n",
      "iteration:851 loss:57649.429675 \n",
      "iteration:852 loss:57649.429675 \n",
      "iteration:853 loss:57649.429675 \n",
      "iteration:854 loss:57649.429675 \n",
      "iteration:855 loss:57649.429675 \n",
      "iteration:856 loss:57649.429675 \n",
      "iteration:857 loss:57649.429675 \n",
      "iteration:858 loss:57649.429675 \n",
      "iteration:859 loss:57649.429675 \n",
      "iteration:860 loss:57649.429675 \n",
      "iteration:861 loss:57649.429675 \n",
      "iteration:862 loss:57649.429675 \n",
      "iteration:863 loss:57649.429675 \n",
      "iteration:864 loss:57649.429675 \n",
      "iteration:865 loss:57649.429675 \n",
      "iteration:866 loss:57649.429675 \n",
      "iteration:867 loss:57649.429675 \n",
      "iteration:868 loss:57649.429675 \n",
      "iteration:869 loss:57649.429675 \n",
      "iteration:870 loss:57649.429675 \n",
      "iteration:871 loss:57649.429675 \n",
      "iteration:872 loss:57649.429675 \n",
      "iteration:873 loss:57649.429675 \n",
      "iteration:874 loss:57649.429675 \n",
      "iteration:875 loss:57649.429675 \n",
      "iteration:876 loss:57649.429675 \n",
      "iteration:877 loss:57649.429675 \n",
      "iteration:878 loss:57649.429675 \n",
      "iteration:879 loss:57649.429675 \n",
      "iteration:880 loss:57649.429675 \n",
      "iteration:881 loss:57649.429675 \n",
      "iteration:882 loss:57649.429675 \n",
      "iteration:883 loss:57649.429675 \n",
      "iteration:884 loss:57649.429675 \n",
      "iteration:885 loss:57649.429675 \n",
      "iteration:886 loss:57649.429675 \n",
      "iteration:887 loss:57649.429675 \n",
      "iteration:888 loss:57649.429675 \n",
      "iteration:889 loss:57649.429675 \n",
      "iteration:890 loss:57649.429675 \n",
      "iteration:891 loss:57649.429675 \n",
      "iteration:892 loss:57649.429675 \n",
      "iteration:893 loss:57649.429675 \n",
      "iteration:894 loss:57649.429675 \n",
      "iteration:895 loss:57649.429675 \n",
      "iteration:896 loss:57649.429675 \n",
      "iteration:897 loss:57649.429675 \n",
      "iteration:898 loss:57649.429675 \n",
      "iteration:899 loss:57649.429675 \n",
      "iteration:900 loss:57649.429675 \n",
      "iteration:901 loss:57649.429675 \n",
      "iteration:902 loss:57649.429675 \n",
      "iteration:903 loss:57649.429675 \n",
      "iteration:904 loss:57649.429675 \n",
      "iteration:905 loss:57649.429675 \n",
      "iteration:906 loss:57649.429675 \n",
      "iteration:907 loss:57649.429675 \n",
      "iteration:908 loss:57649.429675 \n",
      "iteration:909 loss:57649.429675 \n",
      "iteration:910 loss:57649.429675 \n",
      "iteration:911 loss:57649.429675 \n",
      "iteration:912 loss:57649.429675 \n",
      "iteration:913 loss:57649.429675 \n",
      "iteration:914 loss:57649.429675 \n",
      "iteration:915 loss:57649.429675 \n",
      "iteration:916 loss:57649.429675 \n",
      "iteration:917 loss:57649.429675 \n",
      "iteration:918 loss:57649.429675 \n",
      "iteration:919 loss:57649.429675 \n",
      "iteration:920 loss:57649.429675 \n",
      "iteration:921 loss:57649.429675 \n",
      "iteration:922 loss:57649.429675 \n",
      "iteration:923 loss:57649.429675 \n",
      "iteration:924 loss:57649.429675 \n",
      "iteration:925 loss:57649.429675 \n",
      "iteration:926 loss:57649.429675 \n",
      "iteration:927 loss:57649.429675 \n",
      "iteration:928 loss:57649.429675 \n",
      "iteration:929 loss:57649.429675 \n",
      "iteration:930 loss:57649.429675 \n",
      "iteration:931 loss:57649.429675 \n",
      "iteration:932 loss:57649.429675 \n",
      "iteration:933 loss:57649.429675 \n",
      "iteration:934 loss:57649.429675 \n",
      "iteration:935 loss:57649.429675 \n",
      "iteration:936 loss:57649.429675 \n",
      "iteration:937 loss:57649.429675 \n",
      "iteration:938 loss:57649.429675 \n",
      "iteration:939 loss:57649.429675 \n",
      "iteration:940 loss:57649.429675 \n",
      "iteration:941 loss:57649.429675 \n",
      "iteration:942 loss:57649.429675 \n",
      "iteration:943 loss:57649.429675 \n",
      "iteration:944 loss:57649.429675 \n",
      "iteration:945 loss:57649.429675 \n",
      "iteration:946 loss:57649.429675 \n",
      "iteration:947 loss:57649.429675 \n",
      "iteration:948 loss:57649.429675 \n",
      "iteration:949 loss:57649.429675 \n",
      "iteration:950 loss:57649.429675 \n",
      "iteration:951 loss:57649.429675 \n",
      "iteration:952 loss:57649.429675 \n",
      "iteration:953 loss:57649.429675 \n",
      "iteration:954 loss:57649.429675 \n",
      "iteration:955 loss:57649.429675 \n",
      "iteration:956 loss:57649.429675 \n",
      "iteration:957 loss:57649.429675 \n",
      "iteration:958 loss:57649.429675 \n",
      "iteration:959 loss:57649.429675 \n",
      "iteration:960 loss:57649.429675 \n",
      "iteration:961 loss:57649.429675 \n",
      "iteration:962 loss:57649.429675 \n",
      "iteration:963 loss:57649.429675 \n",
      "iteration:964 loss:57649.429675 \n",
      "iteration:965 loss:57649.429675 \n",
      "iteration:966 loss:57649.429675 \n",
      "iteration:967 loss:57649.429675 \n",
      "iteration:968 loss:57649.429675 \n",
      "iteration:969 loss:57649.429675 \n",
      "iteration:970 loss:57649.429675 \n",
      "iteration:971 loss:57649.429675 \n",
      "iteration:972 loss:57649.429675 \n",
      "iteration:973 loss:57649.429675 \n",
      "iteration:974 loss:57649.429675 \n",
      "iteration:975 loss:57649.429675 \n",
      "iteration:976 loss:57649.429675 \n",
      "iteration:977 loss:57649.429675 \n",
      "iteration:978 loss:57649.429675 \n",
      "iteration:979 loss:57649.429675 \n",
      "iteration:980 loss:57649.429675 \n",
      "iteration:981 loss:57649.429675 \n",
      "iteration:982 loss:57649.429675 \n",
      "iteration:983 loss:57649.429675 \n",
      "iteration:984 loss:57649.429675 \n",
      "iteration:985 loss:57649.429675 \n",
      "iteration:986 loss:57649.429675 \n",
      "iteration:987 loss:57649.429675 \n",
      "iteration:988 loss:57649.429675 \n",
      "iteration:989 loss:57649.429675 \n",
      "iteration:990 loss:57649.429675 \n",
      "iteration:991 loss:57649.429675 \n",
      "iteration:992 loss:57649.429675 \n",
      "iteration:993 loss:57649.429675 \n",
      "iteration:994 loss:57649.429675 \n",
      "iteration:995 loss:57649.429675 \n",
      "iteration:996 loss:57649.429675 \n",
      "iteration:997 loss:57649.429675 \n",
      "iteration:998 loss:57649.429675 \n",
      "iteration:999 loss:57649.429675 \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    \n",
    "    for i in range(1000):\n",
    "        total_loss=0\n",
    "        for x,y in data:\n",
    "            _,l = sess.run([optimize,loss],feed_dict={X:x,Y:y})\n",
    "            total_loss+=l\n",
    "        \n",
    "        print(\"iteration:{} loss:{} \".format(i,total_loss))\n",
    "    w, b = sess.run([w, b]) \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.921144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=<unknown> dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxCnRi4hEnBK9iEjE/X/wKipQJo5blgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ccc3c0bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w + b, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
